# Нулевая Задача Проекта

## 1. Выбор модели и обоснование

### Модель обнаружения: YOLOv8
- **Обоснование выбора:**
  - **Реальный тайминг:** YOLOv8 оптимизирована для быстрой обработки изображений, что критически важно для видеопотока в реальном времени.
  - **Предобученные веса:** Модель использует веса, обученные на датасете COCO, что позволяет быстро обнаруживать объекты, в том числе людей, без необходимости обучения с нуля.
  - **Активное сообщество и документация:** Широкое сообщество пользователей и хорошая документация упрощают настройку и устранение возможных проблем.

### Метод трекинга: DeepSORT
- **Обоснование выбора:**
  - **Надёжная ассоциация объектов между кадрами:** DeepSORT эффективно связывает детекции с треками с помощью appearance features и координат.
  - **Комбинация с YOLOv8:** Этот подход уже зарекомендовал себя в задачах трекинга в реальном времени, обеспечивая высокую точность и скорость обработки.

---

## 2. Выбор и подготовка датасета

### Варианты выбора датасета:
- **COCO Dataset:**  
  Используется для детекции объектов, включая людей. Предобученные веса YOLOv8 опираются на этот датасет, что сокращает этапы обучения.

- **MOT Challenge (MOT17/MOT20):**  
  Предназначен для задач многоканального трекинга и включает размеченные видеопоследовательности с людьми. Подходит для проверки алгоритмов трекинга в реальных сценариях.

### Подготовка датасета:
- **Дообучение и тонкая настройка:**  
  Можно комбинировать COCO и MOT датасеты для повышения точности, особенно при специфических условиях видеопотока.
- **Собственный датасет:**  
  Возможно собрать собственные видеозаписи, например, с камер наблюдения, и предварительно аннотировать кадры (вручную или полуавтоматически).

---

## 3. Формат входных и выходных данных

### Входные данные:
- **Видео поток или отдельные кадры:**
  - Форматы: MP4, AVI или поток с веб-камеры.
  - Кадры могут быть представлены в формате BGR (если используется OpenCV) или RGB.

### Выходные данные:
- **Детекции объектов:**
  - Список обнаруженных объектов с координатами bounding boxes в формате `[x, y, width, height]` или `[x1, y1, x2, y2]`.
- **Треки объектов:**
  - Уникальный идентификатор для каждого отслеживаемого объекта.
  - История координат (траектория) для каждого объекта.
- **Статистика:**
  - Общее количество обнаруженных людей.
  - Время нахождения объектов в кадре.
  - Частота входа/выхода объектов и прочая агрегированная информация.

---

## 4. Схема пайплайна

Пайплайн проекта можно разбить на следующие этапы:

1. **Получение видео потока/кадров:**
   - Источник: видеофайл, веб-камера или поток по протоколу RTSP.
2. **Предобработка:**
   - Извлечение кадров.
   - Масштабирование, изменение формата изображения.
   - Нормализация при необходимости.
3. **Обнаружение объектов (YOLOv8):**
   - Получение координат bounding boxes людей на каждом кадре.
4. **Ассоциация и трекинг (DeepSORT):**
   - Ассоциация детекций между кадрами с использованием DeepSORT.
   - Присвоение уникальных идентификаторов и сохранение траекторий.
5. **Подсчет статистики:**
   - Анализ треков для вычисления статистических показателей (общее число объектов, время нахождения в кадре и т.д.).
6. **API для live-визуализации:**
   - Формирование и отправка данных о текущих детекциях и треках через REST API или WebSocket.
7. **Вывод визуализации:**
   - Отображение результатов трекинга: наложение bounding boxes и идентификаторов на видеопоток.
   - Построение графиков или отображение текстовой статистики.


---

## 5. Краткое описание API

### Основные эндпоинты:

1. **`/track` (POST)**
   - **Описание:** Принимает изображение/кадр или ссылку на видео и возвращает данные трекинга.
   - **Формат ответа:**
     - Список детекций с параметрами (`id`, координаты `bbox`, вероятность).
     - Текущие треки с историей координат для каждого объекта.

2. **`/stats` (GET)**
   - **Описание:** Возвращает агрегированную статистику за определённый интервал времени.
   - **Формат ответа:**
     - Общее количество людей, время нахождения в кадре, количество появлений/исчезновений объектов и т.д.

3. **`/live` (WebSocket)**
   - **Описание:** Предоставляет поток обновленных данных трекинга в реальном времени для live-визуализации.
   - **Применение:** Клиентская часть (HTML/JS) подписывается на данный WebSocket для обновления отображаемой информации.

### Технические особенности API:
- **Формат передачи данных:** JSON для REST-запросов.
- **Безопасность:** Возможна авторизация и использование HTTPS.
- **Документация:** Включает краткое описание эндпоинтов, примеры запросов и ответы с указанием форматов данных.
- **Скалируемость:** Проектируется с учетом возможности горизонтального масштабирования за счет модульной архитектуры (разделение обработки детекции, трекинга и статистики).

---

## Заключение

Данное описание нулевой задачи охватывает основные аспекты реализации проекта:
- **Выбор моделей:** YOLOv8 для детекции и DeepSORT для трекинга.
- **Подбор датасета:** COCO и MOT Challenge для повышения точности.
- **Форматы данных:** Четкое определение входных и выходных форматов.
- **Схема пайплайна:** Детальное описание всех этапов обработки видеопотока.
- **API:** Разработка REST API и WebSocket для live-визуализации и подсчета статистики.

Эта структура обеспечит эффективный старт проекта, уделяя особое внимание реальному времени, инженерному качеству и масштабируемости, а также облегчит последующее развёртывание через Docker Compose и интеграцию с кластерной инфраструктурой.


